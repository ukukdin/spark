package Spark_Scala
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

object PartitionFiles {
  def main(args: Array[String]): Unit = {
     val conf = new SparkConf()
              .setAppName("partitionaFiles")
              .setMaster("local")
              
             val sc = new SparkContext(conf)
             val rdd = sc.textFile("dataoutputt.txt")
             rdd.getNumPartitions
             val rdd2 = sc.textFile("NOTICE")
             rdd2.getNumPartitions
             val rdd3 = sc.textFile("dataoutputt.txt,NOTICE")
             rdd3.getNumPartitions
             val rdd4 = sc.textFile("LI*,NO*,RE*")
             rdd.saveAsTextFile("rdd")
             rdd.saveAsTextFile("rdd2")
             rdd.saveAsTextFile("rdd3")
             rdd.saveAsTextFile("rdd4")
             val rdd5 = rdd.union(rdd2).union(rdd3).union(rdd4)
             print(rdd5.getNumPartitions)
             
             val rdd6 = rdd5.map(x=>{Thread.sleep(1); x*x})
  }
}