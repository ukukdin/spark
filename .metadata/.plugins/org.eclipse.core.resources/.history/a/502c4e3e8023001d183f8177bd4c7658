package Spark_Scala


import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

object cachedRDDbyName {
  def main(args: Array[String]): Unit = {
      val conf = new SparkConf()
              .setAppName("ShuffleByRepartition")
              .setMaster("local")
              
             val sc = new SparkContext(conf)
      
      val data = sc.textFile("dataoutputt.txt")
      val distData = data.map(r => r+ "_map")
      
  }
}