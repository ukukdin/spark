package Spark_Scala
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions
object PartFiles {
  def main(args: Array[String]): Unit = {
       val conf = new SparkConf()
				   .setAppName("partF")
				   .setMaster("local")
				   
				   val sc = new SparkContext(conf)
       
       val rdd = sc.parallelize(1 to 1000)
       print(rdd.getNumPartitions)
       val rdd2 = sc.parallelize(1 to 10)
       print(rdd2.getNumPartitions)
       val rdd3 = sc.parallelize(1 to 10000)
       print(rdd3.getNumPartitions)
       val rdd4 = sc.parallelize(1 to 2)
       print(rdd4.getNumPartitions)
  }
}