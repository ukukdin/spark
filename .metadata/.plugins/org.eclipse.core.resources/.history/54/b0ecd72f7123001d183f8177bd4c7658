package Spark_Scala
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions
object PartFiles {
  def main(args: Array[String]): Unit = {
       val conf = new SparkConf()
				   .setAppName("partF")
				   .setMaster("local")
				   
				   val sc = new SparkContext(conf)
       
       val rdd = sc.parallelize(1 to 1000)
       print(rdd.getNumPartitions)
  }
}