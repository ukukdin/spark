package Spark_Scala

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

object CacheSize {
  
  val conf = new SparkConf()
					.setAppName("partF")
					.setMaster("local")

					val sc = new SparkContext(conf)
  
  			val intRdd = sc.parallelize(1 to 10000)
  			intRdd.name = "intRdd"
  			intRdd.cache
  			intRdd.count
  
}